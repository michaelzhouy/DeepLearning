{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:58.591788Z",
     "start_time": "2020-09-01T15:33:57.780321Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算图\n",
    "## 计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.184651Z",
     "start_time": "2020-09-01T15:33:58.594742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "y.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 叶子节点这个属性(还记得张量的属性里面有一个 is_leaf 吗）: **叶子节点：用户创建的节点**， 比如上面的 x 和 w。叶子节点是非常关键的，在上面的正向计算和反向计算中，其实都是依赖于我们叶子节点进行计算的。is_leaf: 指示张量是否是叶子节点。\n",
    "\n",
    "为什么要设置叶子节点的这个概念的？主要是为了节省内存，因为我们在反向传播完了之后，非叶子节点的梯度是默认被释放掉的。我们可以根据上面的那个计算过程，来看看 w，x, a, b, y 的 is_leaf 属性，和它们各自的梯度情况："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.234621Z",
     "start_time": "2020-09-01T15:33:59.189649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_leaf:\n",
      " True True False False False\n",
      "gradient:\n",
      " tensor([5.]) tensor([2.]) None None None\n"
     ]
    }
   ],
   "source": [
    "# 查看叶子结点\n",
    "print(\"is_leaf:\\n\", w.is_leaf, x.is_leaf, a.is_leaf, b.is_leaf, y.is_leaf)\n",
    "# 查看梯度， 默认是只保留叶子节点的梯度的\n",
    "print(\"gradient:\\n\", w.grad, x.grad, a.grad, b.grad, y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.261607Z",
     "start_time": "2020-09-01T15:33:59.237621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient:\n",
      " tensor([5.]) tensor([2.]) tensor([2.]) None None\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "a = torch.add(w, x)\n",
    "a.retain_grad()\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "y.backward()\n",
    "#查看梯度， 默认是只保留叶子节点的梯度的\n",
    "print(\"gradient:\\n\", w.grad, x.grad, a.grad, b.grad, y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. grad_fn：记录创建该张量时所用的方法（函数），记录这个方法主要「用于梯度的求导」。要不然怎么知道具体是啥运算？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.318573Z",
     "start_time": "2020-09-01T15:33:59.264605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_fn:\n",
      " None None <AddBackward0 object at 0x000001B58A3E2C88> <AddBackward0 object at 0x000001B58A3E2C50> <MulBackward0 object at 0x000001B58A3E2C18>\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "a = torch.add(w, x)\n",
    "a.retain_grad()\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# 查看 grad_fn   这个表示怎么得到的\n",
    "print(\"grad_fn:\\n\", w.grad_fn, x.grad_fn, a.grad_fn, b.grad_fn, y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态图\n",
    "根据计算图的搭建方式，可以将计算图分为动态图和静态图。\n",
    "- 静态图：先搭建图，后运算。高效，不灵活（TensorFlow）\n",
    "- 动态图：运算与搭建同时进行。灵活，易调节（Pytorch）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.328571Z",
     "start_time": "2020-09-01T15:33:59.322572Z"
    }
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# # 声明两个常量\n",
    "# w = tf.constant(1.)\n",
    "# x = tf.constant(2.)\n",
    "\n",
    "# # 搭建静态图\n",
    "# a = tf.add(w, x)\n",
    "# b = tf.add(w, 1)\n",
    "# y = tf.multiply(a, b)\n",
    "\n",
    "# # 这时候还没开始计算\n",
    "# print(y)   # Tensor(\"Mul_4:0\", shape=(), dtype=float32)， 只是计算图的一个节点\n",
    "\n",
    "# with tf.Session() as sess:  \n",
    "#     print(sess.run(y))   # 这里才开始进行计算， 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.363552Z",
     "start_time": "2020-09-01T15:33:59.337563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "print(y)    # tensor([6.], grad_fn=<MulBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动求导机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.377541Z",
     "start_time": "2020-09-01T15:33:59.370549Z"
    }
   },
   "outputs": [],
   "source": [
    "y0 = torch.mul(a, b)  # y0=(x + w) * (w + 1)   dy0 / dw = 5\n",
    "y1 =torch.add(a, b)   # y1=(x + w) + (w + 1)   dy1 / dw = 2\n",
    "\n",
    "loss = torch.cat([y0, y1], dim=0)  # [y0, y1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.412519Z",
     "start_time": "2020-09-01T15:33:59.382537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.])\n"
     ]
    }
   ],
   "source": [
    "grad_tensors = torch.tensor([1., 1.])\n",
    "loss.backward(gradient=grad_tensors)    \n",
    "print(w.grad)   #  这时候会是tensor([7.])   5+2\n",
    "\n",
    "# grad_tensors = torch.tensor([1., 2.])\n",
    "# loss.backward(gradient=grad_tensors)    \n",
    "# print(w.grad)   #  这时候会是tensor([9.])   5+2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.436505Z",
     "start_time": "2020-09-01T15:33:59.417520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([6.], grad_fn=<MulBackward0>),)\n",
      "(tensor([2.]),)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3.], requires_grad=True)\n",
    "y = torch.pow(x, 2)  # y = x ^ 2\n",
    "\n",
    "# 一次求导\n",
    "grad_1 = torch.autograd.grad(y, x, create_graph=True)\n",
    "print(grad_1)\n",
    "\n",
    "# 二次求导\n",
    "grad_2 = torch.autograd.grad(grad_1[0], x)\n",
    "print(grad_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.464490Z",
     "start_time": "2020-09-01T15:33:59.439504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.) tensor(1.)\n",
      "tensor(3.) tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.tensor(1.0, requires_grad=True)\n",
    "x2 = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "y1 = x1 * x2\n",
    "y2 = x1 + x2\n",
    "\n",
    "\n",
    "# 同时对多个自变量求导\n",
    "(dy1_dx1, dy1_dx2) = torch.autograd.grad(outputs=y1, inputs=[x1, x2], retain_graph=True)\n",
    "print(dy1_dx1, dy1_dx2)\n",
    "\n",
    "# 如果有多个因变量，相当于把多个因变量的梯度结果求和\n",
    "(dy12_dx1, dy12_dx2) = torch.autograd.grad(outputs=[y1, y2], inputs=[x1, x2])\n",
    "print(dy12_dx1, dy12_dx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 关于 Pytorch 的自动求导系统要注意：\n",
    "\n",
    "梯度不自动清零：就是每一次反向传播，梯度都会叠加上去，这个要注意，举个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.490474Z",
     "start_time": "2020-09-01T15:33:59.469486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.])\n",
      "tensor([10.])\n",
      "tensor([15.])\n",
      "tensor([20.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "for i in range(4):\n",
    "    a = torch.add(w, x)\n",
    "    b = torch.add(w, 1)\n",
    "    y = torch.mul(a, b)\n",
    "    \n",
    "    y.backward()\n",
    "    print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.517459Z",
     "start_time": "2020-09-01T15:33:59.493473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.])\n",
      "tensor([5.])\n",
      "tensor([5.])\n",
      "tensor([5.])\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "for i in range(4):\n",
    "    a = torch.add(w, x)\n",
    "    b = torch.add(w, 1)\n",
    "    y = torch.mul(a, b)\n",
    "    \n",
    "    y.backward()\n",
    "    print(w.grad)\n",
    "    \n",
    "    w.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 依赖于叶子节点的节点，requires_grad 默认为 True，这是啥意思？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.550447Z",
     "start_time": "2020-09-01T15:33:59.520457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True True\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "b = torch.tensor([2.], requires_grad=True)\n",
    "\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "\n",
    "y = torch.mul(a, b)\n",
    "print(w.requires_grad, a.requires_grad, b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 叶子节点不可执行 in-place（这个 in-place 就是原位操作）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.619401Z",
     "start_time": "2020-09-01T15:33:59.555437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879220065768 tensor([], size=(1, 0))\n",
      "1879220061240 tensor([], size=(1, 0))\n",
      "1879220109816 tensor([1.])\n",
      "1879220109816 tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((1, 0))\n",
    "print(id(a), a)\n",
    "\n",
    "a = a + torch.ones((1,))\n",
    "print(id(a), a)\n",
    "\n",
    "# 原地修改\n",
    "a = torch.ones((1,))\n",
    "print(id(a), a)\n",
    "a += torch.ones((1,))\n",
    "print(id(a), a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据生成 这里我们使用随机生成的方式，生成 2 类样本（用 0 和 1 表示）， 每一类样本 100 个， 每一个样本两个特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.652382Z",
     "start_time": "2020-09-01T15:33:59.624399Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"数据生成\"\"\"\n",
    "torch.manual_seed(1)\n",
    "\n",
    "sample_nums = 100\n",
    "mean_value = 1.7\n",
    "bias = 1\n",
    "\n",
    "n_data = torch.ones(sample_nums, 2)\n",
    "x0 = torch.normal(mean_value * n_data, 1) + bias   # 类别0，数据shape=(100,2)\n",
    "y0 = torch.zeros(sample_nums)                      # 类别0，数据shape=(100,1)\n",
    "\n",
    "x1 = torch.normal(-mean_value * n_data, 1) + bias  # 类别1，数据shape=(100,2)\n",
    "y1 = torch.ones(sample_nums)                       # 类别1，数据shape=(100,1) \n",
    "\n",
    "train_x = torch.cat([x0, x1], dim=0)\n",
    "train_y = torch.cat([y0, y1], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 建立模型 这里我们使用两种方式建立我们的逻辑回归模型，一种是 Pytorch 的 sequential 方式，这种方式就是简单，易懂，就类似于搭积木一样，一层一层往上搭。另一种方式是继承 nn.Module 这个类搭建模型，这种方式非常灵活，能够搭建各种复杂的网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.668371Z",
     "start_time": "2020-09-01T15:33:59.656380Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"建立模型\"\"\"\n",
    "class LR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LR, self).__init__()\n",
    "        self.features = torch.nn.Linear(2, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "lr_net = LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.689360Z",
     "start_time": "2020-09-01T15:33:59.671371Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_net = torch.nn.Sequential(torch.nn.Linear(2, 1),\n",
    "                             torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 选择损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.711348Z",
     "start_time": "2020-09-01T15:33:59.692359Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"x选择损失函数\"\"\"\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 选择优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:33:59.721342Z",
     "start_time": "2020-09-01T15:33:59.715344Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"选择优化器\"\"\"\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(lr_net.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 迭代训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T15:37:36.487078Z",
     "start_time": "2020-09-01T15:37:36.228808Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-20fece62aa22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'class 1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"模型训练\"\"\"\n",
    "for iteration in range(1000):\n",
    "    # 前向传播\n",
    "    y_pred = lr_net(train_x)\n",
    "    \n",
    "    # 计算loss\n",
    "    loss = loss_fn(y_pred.squeeze(), train_y)\n",
    "    \n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新参数\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 绘图\n",
    "    if iteration % 20 == 0:\n",
    "\n",
    "        mask = y_pred.ge(0.5).float().squeeze()  # 以0.5为阈值进行分类\n",
    "        correct = (mask == train_y).sum()  # 计算正确预测的样本个数\n",
    "        acc = correct.item() / train_y.size(0)  # 计算分类准确率\n",
    "\n",
    "        plt.scatter(x0.data.numpy()[:, 0], x0.data.numpy()[:, 1], c='r', label='class 0')\n",
    "        plt.scatter(x1.data.numpy()[:, 0], x1.data.numpy()[:, 1], c='b', label='class 1')\n",
    "\n",
    "        print(lr_net.named_parameters()[0])\n",
    "        print(lr_net.parameters()[0])\n",
    "        \n",
    "        for name,parameters in lr_net.named_parameters():\n",
    "            print(name,':',parameters)\n",
    "        for parameters in lr_net.parameters():\n",
    "            print(parameters)\n",
    "        w0, w1 = lr_net.parameters()[0], lr_net.parameters()[1]\n",
    "        w0, w1 = float(w0.item()), float(w1.item())\n",
    "        plot_b = float(lr_net.parameters.bias[0].item())\n",
    "        plot_x = np.arange(-6, 6, 0.1)\n",
    "        plot_y = (-w0 * plot_x - plot_b) / w1\n",
    "\n",
    "        plt.xlim(-5, 7)\n",
    "        plt.ylim(-7, 7)\n",
    "        plt.plot(plot_x, plot_y)\n",
    "\n",
    "        plt.text(-5, 5, 'Loss=%.4f' % loss.data.numpy(), fontdict={'size': 20, 'color': 'red'})\n",
    "        plt.title(\"Iteration: {}\\nw0:{:.2f} w1:{:.2f} b: {:.2f} accuracy:{:.2%}\".format(iteration, w0, w1, plot_b, acc))\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "\n",
    "        if acc > 0.99:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
